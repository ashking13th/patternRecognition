{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, argparse, math, random\n",
    "from datetime import datetime\n",
    "\n",
    "ka_test_folder = \"../dataset/Test/ka\"\n",
    "kAA_test_folder = \"../dataset/Test/kAA\"\n",
    "kha_test_folder = \"../dataset/Test/kha\"\n",
    "\n",
    "ka_train_folder = \"../dataset/Train/ka\"\n",
    "kAA_train_folder = \"../dataset/Train/kAA\"\n",
    "kha_train_folder = \"../dataset/Train/kha\"\n",
    "\n",
    "# clusters = 2\n",
    "\n",
    "meanPath=\"../dataset/prep/kmeans/\"\n",
    "\n",
    "outputPath = \"../dataset/prep/codebook/\"\n",
    "\n",
    "trainData = [] # training data\n",
    "dataLen = []\n",
    "testData = []\n",
    "testLen = []\n",
    "means = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383  files read in folder  ../dataset/Train/ka\n",
      "510  files read in folder  ../dataset/Train/kAA\n",
      "61  files read in folder  ../dataset/Train/kha\n",
      "96  files read in folder  ../dataset/Test/ka\n",
      "127  files read in folder  ../dataset/Test/kAA\n",
      "15  files read in folder  ../dataset/Test/kha\n"
     ]
    }
   ],
   "source": [
    "def fileHandle(fileName):\n",
    "    wholeData = []\n",
    "    file = open(fileName)\n",
    "    for line in file:\n",
    "        teLine = line.rstrip('\\n ').split(' ')\n",
    "        nLine = [float(i) for i in teLine]\n",
    "        nLine = np.array(nLine)\n",
    "        wholeData.append(nLine)\n",
    "    file.close()\n",
    "    return wholeData\n",
    "\n",
    "# Reading all the example sets in a folder\\n\",\n",
    "def readFolder(folder):\n",
    "    data = []\n",
    "    count = 0\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        for f in files:\n",
    "#             print(\"Reading: \",f)\n",
    "            path = os.path.relpath(os.path.join(root, f), \".\")\n",
    "    #         target = os.path.relpath(os.path.join(root, os.path.splitext(f)[0]))\n",
    "            data.append(fileHandle(path))\n",
    "            count += 1\n",
    "    print(count,\" files read in folder \",folder)\n",
    "    return data\n",
    "\n",
    "# Reading all the training data\n",
    "trainData.append(readFolder(ka_train_folder))\n",
    "dataLen.append(len(trainData[0]))\n",
    "trainData.append(readFolder(kAA_train_folder))\n",
    "dataLen.append(len(trainData[1]))\n",
    "trainData.append(readFolder(kha_train_folder))\n",
    "dataLen.append(len(trainData[2]))\n",
    "\n",
    "testData.append(readFolder(ka_test_folder))\n",
    "testLen.append(len(testData[0]))\n",
    "testData.append(readFolder(kAA_test_folder))\n",
    "testLen.append(len(testData[1]))\n",
    "testData.append(readFolder(kha_test_folder))\n",
    "testLen.append(len(testData[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeCB(classIndex, name, values, clusters):\n",
    "    targetPath = outputPath + name + \"_c\" + str(classIndex) + \"_\" + str(clusters) + \".cb\"\n",
    "\n",
    "    if not os.path.exists(os.path.dirname(targetPath)):\n",
    "        try:\n",
    "            os.makedirs(os.path.dirname(targetPath))\n",
    "        except OSError as exc:  # Guard against race condition\n",
    "            if exc.errno != errno.EEXIST:\n",
    "                raise\n",
    "    try:\n",
    "        print(\"target File: \", targetPath)\n",
    "        outfile = open(targetPath, \"w\")\n",
    "    except IOError:\n",
    "        print(\"File not created !!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "\n",
    "    for value in values:\n",
    "        for feature in value:\n",
    "            outfile.write(str(feature)+\" \")\n",
    "        outfile.write(\"\\n\")\n",
    "    outfile.close()\n",
    "    print(\"Done !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters:  2\n",
      "train data\n",
      "target File:  ../dataset/prep/codebook/train_c0_2.cb\n",
      "Done !\n",
      "target File:  ../dataset/prep/codebook/train_c1_2.cb\n",
      "Done !\n",
      "target File:  ../dataset/prep/codebook/train_c2_2.cb\n",
      "Done !\n",
      "test data\n",
      "target File:  ../dataset/prep/codebook/test_c0_2.cb\n",
      "Done !\n",
      "target File:  ../dataset/prep/codebook/test_c1_2.cb\n",
      "Done !\n",
      "target File:  ../dataset/prep/codebook/test_c2_2.cb\n",
      "Done !\n",
      "Clusters:  4\n",
      "train data\n",
      "target File:  ../dataset/prep/codebook/train_c0_4.cb\n",
      "Done !\n",
      "target File:  ../dataset/prep/codebook/train_c1_4.cb\n",
      "Done !\n",
      "target File:  ../dataset/prep/codebook/train_c2_4.cb\n",
      "Done !\n",
      "test data\n",
      "target File:  ../dataset/prep/codebook/test_c0_4.cb\n",
      "Done !\n",
      "target File:  ../dataset/prep/codebook/test_c1_4.cb\n",
      "Done !\n",
      "target File:  ../dataset/prep/codebook/test_c2_4.cb\n",
      "Done !\n",
      "Clusters:  8\n",
      "train data\n",
      "target File:  ../dataset/prep/codebook/train_c0_8.cb\n",
      "Done !\n",
      "target File:  ../dataset/prep/codebook/train_c1_8.cb\n",
      "Done !\n",
      "target File:  ../dataset/prep/codebook/train_c2_8.cb\n",
      "Done !\n",
      "test data\n",
      "target File:  ../dataset/prep/codebook/test_c0_8.cb\n",
      "Done !\n",
      "target File:  ../dataset/prep/codebook/test_c1_8.cb\n",
      "Done !\n",
      "target File:  ../dataset/prep/codebook/test_c2_8.cb\n",
      "Done !\n",
      "Clusters:  16\n",
      "train data\n",
      "target File:  ../dataset/prep/codebook/train_c0_16.cb\n",
      "Done !\n",
      "target File:  ../dataset/prep/codebook/train_c1_16.cb\n",
      "Done !\n",
      "target File:  ../dataset/prep/codebook/train_c2_16.cb\n",
      "Done !\n",
      "test data\n",
      "target File:  ../dataset/prep/codebook/test_c0_16.cb\n",
      "Done !\n",
      "target File:  ../dataset/prep/codebook/test_c1_16.cb\n",
      "Done !\n",
      "target File:  ../dataset/prep/codebook/test_c2_16.cb\n",
      "Done !\n",
      "Clusters:  32\n",
      "train data\n",
      "target File:  ../dataset/prep/codebook/train_c0_32.cb\n",
      "Done !\n",
      "target File:  ../dataset/prep/codebook/train_c1_32.cb\n",
      "Done !\n",
      "target File:  ../dataset/prep/codebook/train_c2_32.cb\n",
      "Done !\n",
      "test data\n",
      "target File:  ../dataset/prep/codebook/test_c0_32.cb\n",
      "Done !\n",
      "target File:  ../dataset/prep/codebook/test_c1_32.cb\n",
      "Done !\n",
      "target File:  ../dataset/prep/codebook/test_c2_32.cb\n",
      "Done !\n",
      "CODEBOOK complete\n"
     ]
    }
   ],
   "source": [
    "clusters = 1\n",
    "for i in range(5):\n",
    "    clusters *= 2\n",
    "    print(\"Clusters: \",clusters)\n",
    "    global means\n",
    "    means = fileHandle(meanPath+str(clusters)+\".kmeans\")\n",
    "#     codes = []\n",
    "    print(\"train data\")\n",
    "    for classIndex in range(3):\n",
    "#         print(\"class: \",classIndex)\n",
    "        classCodes = []\n",
    "        for file in trainData[classIndex]:\n",
    "            fileCode = []\n",
    "            for vectIndex in range(len(file)):\n",
    "                vectNorm = np.zeros(clusters)\n",
    "                for i in range(clusters):\n",
    "                    vectNorm[i] = np.linalg.norm(means[i]-file[vectIndex])\n",
    "                fileCode.append(np.argmin(vectNorm))\n",
    "            classCodes.append(fileCode)\n",
    "        writeCB(classIndex, \"train\", classCodes, clusters)\n",
    "    print(\"test data\")\n",
    "    for classIndex in range(3):\n",
    "#         print(\"class: \",classIndex)\n",
    "        classCodes = []\n",
    "        for file in testData[classIndex]:\n",
    "            fileCode = []\n",
    "            for vectIndex in range(len(file)):\n",
    "                vectNorm = np.zeros(clusters)\n",
    "                for i in range(clusters):\n",
    "                    vectNorm[i] = np.linalg.norm(means[i]-file[vectIndex])\n",
    "                fileCode.append(np.argmin(vectNorm))\n",
    "            classCodes.append(fileCode)\n",
    "        writeCB(classIndex, \"test\", classCodes, clusters)\n",
    "print(\"CODEBOOK complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
